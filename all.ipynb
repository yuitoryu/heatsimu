{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T01:28:38.913641Z",
     "start_time": "2025-05-07T01:28:38.909335Z"
    }
   },
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# from time import time\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:38:49.389830Z",
     "start_time": "2025-05-06T15:38:49.378730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BC_2D:\n",
    "    def __init__(self, left, right, up, down):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            left, right, up, down: (alpha, beta, f(t))\n",
    "        \"\"\"\n",
    "        # alpha*u + beta*u_x + gamma*u_y = f(t)\n",
    "        self.left_alpha, self.left_beta, self.left_func = left\n",
    "        self.right_alpha, self.right_beta, self.right_func = right\n",
    "        self.up_alpha, self.up_beta, self.up_func = up\n",
    "        self.down_alpha, self.down_beta, self.down_func = down\n",
    "\n",
    "    def apply(self, simu):\n",
    "        gamma_left = self.left_beta / simu.dx\n",
    "        gamma_right = self.right_beta / simu.dx\n",
    "        gamma_up = self.up_beta / simu.dx\n",
    "        gamma_down = self.down_beta / simu.dx\n",
    "\n",
    "        simu.grid[1:-1,0] = (self.left_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_left * simu.grid[1:-1,1]) / (self.left_alpha - gamma_left)\n",
    "\n",
    "\n",
    "        # Right boundary\n",
    "        simu.grid[1:-1,-1] = (self.right_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_right * simu.grid[1:-1,-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "        # Left boundary\n",
    "        simu.grid[0,1:-1] = (self.up_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_up * simu.grid[1,1:-1]) / (self.up_alpha - gamma_up)\n",
    "\n",
    "        # Down boundary\n",
    "        simu.grid[-1,1:-1] = (self.down_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_down * simu.grid[-2,1:-1]) / (self.down_alpha + gamma_down)\n"
   ],
   "id": "c79d198d6620c4f8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:39:11.920531Z",
     "start_time": "2025-05-06T15:39:11.912909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ContConduct:\n",
    "    def __init__(self, c_func):\n",
    "        self.c_func = c_func\n",
    "        self.map = None\n",
    "\n",
    "    def make_conduct_map(self, simu):\n",
    "        # Initialize conduct map\n",
    "        self.map = torch.zeros(simu.grid.shape[0], simu.grid.shape[1], device=simu.device, dtype=simu.dtype)\n",
    "\n",
    "        # Get coordinates\n",
    "        x_coord = torch.arange(simu.x_grid, requires_grad=False, device=simu.device).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "        y_coord = torch.arange(simu.y_grid, requires_grad=False, device=simu.device).unsqueeze(1).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "\n",
    "        # Apply conductivity for interior\n",
    "        self.map[1:-1,1:-1] = self.c_func(x_coord, y_coord)\n",
    "\n",
    "        # Apply conductivity for boundary\n",
    "        self.map[0,:] = self.map[1,:] # up\n",
    "        self.map[-1,:] = self.map[-2,:] # down\n",
    "        self.map[:,0] = self.map[:,1] # left\n",
    "        self.map[:,-1] = self.map[:,-2] # right\n",
    "\n",
    "        # Compute harmonic mean conductivity\n",
    "        # left\n",
    "        self.map_left = 2 * self.map[1:-1,1:-1] * self.map[0:-2, 1:-1] / (self.map[1:-1,1:-1] + self.map[0:-2, 1:-1])\n",
    "\n",
    "        # right\n",
    "        self.map_right = 2 * self.map[1:-1,1:-1] * self.map[2:, 1:-1] / (self.map[1:-1,1:-1] + self.map[2, 1:-1])\n",
    "\n",
    "        # up\n",
    "        self.map_up = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 0:-2] / (self.map[1:-1,1:-1] + self.map[1:-1, 0:-2])\n",
    "\n",
    "        # down\n",
    "        self.map_down = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 2:] / (self.map[1:-1,1:-1] + self.map[1:-1, 2:])\n",
    "\n",
    "        self.merge_map = torch.stack([\n",
    "            self.map_left,\n",
    "            self.map_right,\n",
    "            self.map_up,\n",
    "            self.map_down\n",
    "        ], dim=0).unsqueeze(0)\n",
    "\n",
    "    def sanity_check(self, simu):\n",
    "        max_conduct = torch.max(self.map)\n",
    "        factor = simu.dt * max_conduct * 2 / simu.dx**2\n",
    "        if factor > 0.5:\n",
    "            raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n"
   ],
   "id": "44c4a2919322df04",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:42:37.917307Z",
     "start_time": "2025-05-06T15:42:37.903952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Heat2dSimu:\n",
    "    def __init__(self, map_shape, dx, total_time, tstep, bc, ic, c, plot_step, Q=0, device='cpu', do_progress_bar=True, dtype=torch.float32, if_plot=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            map_shape (tuple): Physical size of the 2D domain.\n",
    "            step (float): Step size of *interior* points (excluding boundaries).\n",
    "            total_time (float): End time for the simulation.\n",
    "            tstep (int): Step size of time.\n",
    "            bc (iterable): Boundary condition with 4 elements. Order: up, r down, left, right.\n",
    "            ic (callable): Function for initial condition.\n",
    "            c (float): Diffusion coefficient.\n",
    "            plot_step (int): How often (in steps) to plot the solution.\n",
    "            device (str): 'cpu' or 'cuda', which device to use for Tensor operations.\n",
    "        \"\"\"\n",
    "        self.grid = None\n",
    "        self.grid_bach = None\n",
    "        self.map_shape = map_shape\n",
    "        self.dx = dx\n",
    "        self.total_time = total_time\n",
    "        self.dt = tstep\n",
    "        self.bc = bc\n",
    "        self.ic = ic\n",
    "        self.c = c\n",
    "        self.plot_step = plot_step\n",
    "        self.do_progress_bar = do_progress_bar\n",
    "        self.Q = self.make_heat_source_func(Q)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.conv = None\n",
    "        self.decide_computation_mode()\n",
    "        self.cur_time = 0\n",
    "        self.if_plot = if_plot\n",
    "        self.do_progress_bar = do_progress_bar\n",
    "\n",
    "\n",
    "\n",
    "        # Check device\n",
    "        if torch.cuda.is_available() and device != 'cpu':\n",
    "            self.device = device\n",
    "\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "\n",
    "        self.make_grid()\n",
    "\n",
    "        # Useful preload data\n",
    "        self.x_coord_tensor = torch.arange(self.x_grid, requires_grad=False, device=self.device).expand(self.y_grid, self.x_grid) * self.dx\n",
    "        self.y_coord_tensor = torch.arange(self.y_grid, requires_grad=False, device=self.device).unsqueeze(1).expand(self.y_grid, self.x_grid) * self.dx\n",
    "\n",
    "        # Some initialization\n",
    "        self.set_ic()\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.make_conduct_map(self)\n",
    "\n",
    "        # Sanity check\n",
    "        self.sanity_check()\n",
    "\n",
    "    def sanity_check(self):\n",
    "        # Check conductivity\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.sanity_check(self)\n",
    "        else:\n",
    "            factor = self.dt * c * 2 / self.dx**2\n",
    "            if factor > 0.5:\n",
    "                raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n",
    "        # Check dt size setting\n",
    "        if self.dt > self.total_time/2:\n",
    "            raise ValueError('The time step is too big.')\n",
    "\n",
    "        # Check dx size setting\n",
    "        if self.dt > self.total_time/3:\n",
    "            raise ValueError('The grid step is too big.')\n",
    "\n",
    "    def make_heat_source_func(self, Q):\n",
    "        if callable(Q):\n",
    "            return torch.compile(Q)\n",
    "        else:\n",
    "            def func(x, y, t):\n",
    "                return Q\n",
    "            return torch.compile(func)\n",
    "\n",
    "    def set_ic(self):\n",
    "        # print(self.grid[1:-1,1:-1].shape)\n",
    "        self.grid[1:-1,1:-1] = self.ic(self.x_coord_tensor, self.y_coord_tensor)\n",
    "\n",
    "    def set_bc(self):\n",
    "        self.bc.apply(self)\n",
    "\n",
    "    def make_grid(self):\n",
    "        # Get size of grid\n",
    "        self.x_grid = math.ceil(self.map_shape[1] / self.dx)\n",
    "        self.y_grid = math.ceil(self.map_shape[0] / self.dx)\n",
    "        self.grid = torch.zeros(self.y_grid+2, self.x_grid+2, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        # For convenience, prevent overhead for unsqueeze\n",
    "        self.grid_ch = self.grid.unsqueeze(0).unsqueeze(0).expand(1,1,-1,-1)\n",
    "\n",
    "    def make_conv_core_continuous(self):\n",
    "        self.conv = [nn.Conv2d(1, 1, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype) for i in range(4)]\n",
    "        dt_dx2 = self.dt / (self.dx ** 2)\n",
    "        kernel = [ [[[ [0,0,0], [1,-1,0], [0,0,0] ]]],\n",
    "                   [[[ [0,0,0], [0,-1,1], [0,0,0] ]]],\n",
    "                   [[[ [0,1,0], [0,-1,0], [0,0,0] ]]],\n",
    "                   [[[ [0,0,0], [0,-1,0], [0,1,0] ]]],]\n",
    "        with torch.no_grad():\n",
    "            for i in range(4):\n",
    "                self.conv[i].weight[:] = torch.tensor(kernel[i], device=self.device, dtype=self.dtype) * dt_dx2\n",
    "\n",
    "\n",
    "    def make_conv_core_const(self):\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype)\n",
    "        dt_dx2 = self.dt / (self.dx**2)\n",
    "        kernel = torch.tensor([\n",
    "            [[ [0,1,0], [1,-4,1], [0,1,0] ]],\n",
    "        ], device=self.device, dtype=self.dtype) * dt_dx2 * self.c\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = kernel\n",
    "\n",
    "    def decide_computation_mode(self):\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.update = self.update_continuous\n",
    "            self.make_conv_core_continuous()\n",
    "        else:\n",
    "            self.update = self.update_const\n",
    "            self.make_conv_core_const()\n",
    "\n",
    "    def update_continuous(self):\n",
    "        with torch.inference_mode():\n",
    "            diff0 = self.conv[0](self.grid_ch)\n",
    "            diff1 = self.conv[1](self.grid_ch)\n",
    "            diff2 = self.conv[2](self.grid_ch)\n",
    "            diff3 = self.conv[3](self.grid_ch)\n",
    "\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff0 + diff1 + diff2 + diff3 + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "\n",
    "    def update_const(self):\n",
    "        with torch.inference_mode():\n",
    "            diff = self.conv(self.grid_ch)\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    # @torch.compile\n",
    "    def start(self):\n",
    "        saved = []\n",
    "        append = saved.append\n",
    "        cur_max = -float('inf')\n",
    "        cur_min = float('inf')\n",
    "        with torch.inference_mode():\n",
    "            for step in tqdm(range( int(self.total_time/self.dt) ),disable=not self.do_progress_bar):\n",
    "                self.set_bc()\n",
    "                self.update()\n",
    "                self.cur_time += self.dt\n",
    "\n",
    "                if step % self.plot_step == 0:\n",
    "                    copied = self.grid[1:-1,1:-1].clone().to('cpu', non_blocking=True)\n",
    "                    if self.dtype == torch.bfloat16:\n",
    "                        copied = copied.to(dtype=torch.float32)\n",
    "                    append(copied)\n",
    "\n",
    "                    this_max = torch.max(copied)\n",
    "                    if cur_max < this_max:\n",
    "                        cur_max = this_max\n",
    "\n",
    "                    this_min = torch.min(copied)\n",
    "                    if cur_min > this_min:\n",
    "                        cur_min = this_min\n",
    "\n",
    "        # Append the very final result\n",
    "        copied = self.grid[1:-1,1:-1].clone().to('cpu')\n",
    "        if self.dtype == torch.bfloat16:\n",
    "            copied = copied.to(dtype=torch.float32)\n",
    "        append(copied)\n",
    "\n",
    "        if self.if_plot:\n",
    "            fig, axis = plt.subplots()\n",
    "\n",
    "\n",
    "            pcm = axis.pcolormesh(self.grid.to(dtype=torch.float32).cpu().numpy()[1:-1,1:-1], cmap=plt.cm.jet,\n",
    "                                  vmin=float(cur_min), vmax=float(cur_max))\n",
    "            plt.colorbar(pcm, ax=axis)\n",
    "            axis.set_xlabel('x grids')\n",
    "            axis.set_ylabel('y grids')\n",
    "\n",
    "\n",
    "\n",
    "            for i, data in enumerate(saved):\n",
    "                pcm.set_array(data.numpy())\n",
    "                axis.set_title(f'Distribution at t={i * self.plot_step * self.dt:.4f}')\n",
    "                plt.pause(0.01)\n",
    "\n",
    "            plt.show()\n"
   ],
   "id": "80cbc62867b5222d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:42:38.309226Z",
     "start_time": "2025-05-06T15:42:38.301693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "map_shape=(torch.pi, torch.pi)\n",
    "dx = 0.05\n",
    "total_time=1\n",
    "dt=0.00005\n",
    "# dt = 0.05\n",
    "\n",
    "\n",
    "def ic(x,y):\n",
    "    return torch.sin(x) * torch.sin(y)\n",
    "    # return torch.sin(x)\n",
    "    # return 0\n",
    "c=0.5\n",
    "plot_step=100\n",
    "\n",
    "def Q(x,y,t):\n",
    "    # res = -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5\n",
    "    # if t < 0.5:\n",
    "    #     return res\n",
    "    # return -res\n",
    "    return -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5 * math.sin(t*torch.pi*8)\n",
    "\n",
    "factor = dt*c*2/dx**2\n",
    "print(factor)\n",
    "\n",
    "\n",
    "def func(x,y):\n",
    "    return 0.5\n",
    "con = ContConduct(func)\n",
    "\n",
    "\n",
    "def func2(x,y,t):\n",
    "    # return (torch.where(y < torch.pi/5, -1, 1) + torch.where(y > 2*torch.pi/5, -1, 1) - 1\n",
    "    #         + torch.where(y < 3*torch.pi/5, -1, 1) + torch.where(y > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(y < torch.pi/4, 0, 1) + torch.where(y > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "\n",
    "def func3(x,y,t):\n",
    "    # return (torch.where(x < torch.pi/5, -1, 1) + torch.where(x > 2*torch.pi/5, -1, 1) - 1 +\n",
    "    #         torch.where(x < 3*torch.pi/5, -1, 1) + torch.where(x > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(x < torch.pi/4, 0, 1) + torch.where(x > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "bc= BC_2D((1,0,func2),(1,0,func2),(1,0,func3),(1,0,func3))\n"
   ],
   "id": "268ffe60b7bf8554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019999999999999997\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T15:51:11.927130Z",
     "start_time": "2025-05-06T15:46:30.158119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====================================================================================')\n",
    "print('Simulation seesion benchmark on constant conductivity without optimization')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_plot=False)\n",
    "%timeit  test.start()\n",
    "print('====================================================================================')\n",
    "print('Simulation seesion benchmark on constant conductivity without optimization')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_plot=False)\n",
    "%timeit  test.start()\n",
    "print('====================================================================================')"
   ],
   "id": "8d94906388ba3071",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Simulation seesion benchmark on constant conductivity without optimization\n",
      "16.6 s ± 380 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "====================================================================================\n",
      "Simulation seesion benchmark on constant conductivity without optimization\n",
      "18.1 s ± 297 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:28:44.089799Z",
     "start_time": "2025-05-07T01:28:41.585575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BC_2D:\n",
    "    def __init__(self, left, right, up, down):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            left, right, up, down: (alpha, beta, f(t))\n",
    "        \"\"\"\n",
    "        # alpha*u + beta*u_x + gamma*u_y = f(t)\n",
    "        self.left_alpha, self.left_beta, self.left_func = left\n",
    "        self.right_alpha, self.right_beta, self.right_func = right\n",
    "        self.up_alpha, self.up_beta, self.up_func = up\n",
    "        self.down_alpha, self.down_beta, self.down_func = down\n",
    "\n",
    "    def sanity_check(self):\n",
    "        left = self.left_alpha == 0 and self.left_beta == 0\n",
    "        right = self.right_alpha == 0 and self.right_beta == 0\n",
    "        up = self.up_alpha == 0 and self.up_beta == 0\n",
    "        down = self.down_alpha == 0 and self.down_beta == 0\n",
    "        if not (left and right and up and down):\n",
    "            raise ValueError('Check the boundary conditions. You cannot have alpha and beta be 0 zt the same time.')\n",
    "\n",
    "    @torch.compile(fullgraph=True)\n",
    "    def apply(self, simu):\n",
    "        gamma_left = self.left_beta / simu.dx\n",
    "        gamma_right = self.right_beta / simu.dx\n",
    "        gamma_up = self.up_beta / simu.dx\n",
    "        gamma_down = self.down_beta / simu.dx\n",
    "\n",
    "        simu.grid[1:-1,0] = (self.left_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_left * simu.grid[1:-1,1]) / (self.left_alpha - gamma_left)\n",
    "\n",
    "\n",
    "        # Right boundary\n",
    "        simu.grid[1:-1,-1] = (self.right_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_right * simu.grid[1:-1,-2]) / (self.right_alpha + gamma_right)\n",
    "\n",
    "        # Left boundary\n",
    "        simu.grid[0,1:-1] = (self.up_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) - gamma_up * simu.grid[1,1:-1]) / (self.up_alpha - gamma_up)\n",
    "\n",
    "        # Down boundary\n",
    "        simu.grid[-1,1:-1] = (self.down_func(simu.x_coord_tensor[0,:], simu.y_coord_tensor[:,0], simu.cur_time) + gamma_down * simu.grid[-2,1:-1]) / (self.down_alpha + gamma_down)\n",
    "\n",
    "class ContConduct:\n",
    "    def __init__(self, c_func):\n",
    "        self.c_func = c_func\n",
    "        self.map = None\n",
    "\n",
    "    @torch.compile\n",
    "    def make_conduct_map(self, simu):\n",
    "        # Initialize conduct map\n",
    "        self.map = torch.zeros(simu.grid.shape[0], simu.grid.shape[1], device=simu.device, dtype=simu.dtype)\n",
    "\n",
    "        # Get coordinates\n",
    "        x_coord = torch.arange(simu.x_grid, requires_grad=False, device=simu.device).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "        y_coord = torch.arange(simu.y_grid, requires_grad=False, device=simu.device).unsqueeze(1).expand(simu.y_grid, simu.x_grid) * simu.dx\n",
    "\n",
    "        # Apply conductivity for interior\n",
    "        self.map[1:-1,1:-1] = self.c_func(x_coord, y_coord)\n",
    "\n",
    "        # Apply conductivity for boundary\n",
    "        self.map[0,:] = self.map[1,:] # up\n",
    "        self.map[-1,:] = self.map[-2,:] # down\n",
    "        self.map[:,0] = self.map[:,1] # left\n",
    "        self.map[:,-1] = self.map[:,-2] # right\n",
    "\n",
    "        # Compute harmonic mean conductivity\n",
    "        # left\n",
    "        self.map_left = 2 * self.map[1:-1,1:-1] * self.map[0:-2, 1:-1] / (self.map[1:-1,1:-1] + self.map[0:-2, 1:-1])\n",
    "\n",
    "        # right\n",
    "        self.map_right = 2 * self.map[1:-1,1:-1] * self.map[2:, 1:-1] / (self.map[1:-1,1:-1] + self.map[2, 1:-1])\n",
    "\n",
    "        # up\n",
    "        self.map_up = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 0:-2] / (self.map[1:-1,1:-1] + self.map[1:-1, 0:-2])\n",
    "\n",
    "        # down\n",
    "        self.map_down = 2 * self.map[1:-1,1:-1] * self.map[1:-1, 2:] / (self.map[1:-1,1:-1] + self.map[1:-1, 2:])\n",
    "\n",
    "        self.merge_map = torch.stack([\n",
    "            self.map_left,\n",
    "            self.map_right,\n",
    "            self.map_up,\n",
    "            self.map_down\n",
    "        ], dim=0).unsqueeze(0)\n",
    "\n",
    "    def sanity_check(self, simu):\n",
    "        max_conduct = torch.max(self.map)\n",
    "        factor = simu.dt * max_conduct * 2 / simu.dx**2\n",
    "        if factor > 0.5:\n",
    "            raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n",
    "class Heat2dSimu:\n",
    "    def __init__(self, map_shape, dx, total_time, tstep, bc, ic, c, plot_step, Q=0, device='cpu', do_progress_bar=True, dtype=torch.float32, if_plot=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            map_shape (tuple): Physical size of the 2D domain.\n",
    "            step (float): Step size of *interior* points (excluding boundaries).\n",
    "            total_time (float): End time for the simulation.\n",
    "            tstep (int): Step size of time.\n",
    "            bc (iterable): Boundary condition with 4 elements. Order: up, r down, left, right.\n",
    "            ic (callable): Function for initial condition.\n",
    "            c (float): Diffusion coefficient.\n",
    "            plot_step (int): How often (in steps) to plot the solution.\n",
    "            device (str): 'cpu' or 'cuda', which device to use for Tensor operations.\n",
    "        \"\"\"\n",
    "        self.grid = None\n",
    "        self.grid_bach = None\n",
    "        self.map_shape = map_shape\n",
    "        self.dx = dx\n",
    "        self.total_time = total_time\n",
    "        self.dt = tstep\n",
    "        self.bc = bc\n",
    "        self.ic = ic\n",
    "        self.c = c\n",
    "\n",
    "        # Sanity check\n",
    "\n",
    "\n",
    "        self.plot_step = plot_step\n",
    "        self.do_progress_bar = do_progress_bar\n",
    "        self.Q = self.make_heat_source_func(Q)\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.conv = None\n",
    "        self.decide_computation_mode()\n",
    "        self.cur_time = 0\n",
    "        self.if_plot = if_plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Check device\n",
    "        if torch.cuda.is_available() and device != 'cpu':\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        self.make_grid()\n",
    "\n",
    "        # Useful preload data\n",
    "        self.x_coord_tensor = torch.arange(self.x_grid, requires_grad=False, device=self.device).expand(self.y_grid, self.x_grid) * self.dx\n",
    "        self.y_coord_tensor = torch.arange(self.y_grid, requires_grad=False, device=self.device).unsqueeze(1).expand(self.y_grid, self.x_grid) * self.dx\n",
    "\n",
    "        # Some initialization\n",
    "        self.set_ic()\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.make_conduct_map(self)\n",
    "\n",
    "        self.sanity_check()\n",
    "\n",
    "\n",
    "\n",
    "    def sanity_check(self):\n",
    "        # Check conductivity\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.c.sanity_check(self)\n",
    "        else:\n",
    "            factor = self.dt * c * 2 / self.dx**2\n",
    "            if factor > 0.5:\n",
    "                raise ValueError(f'Improper setting for time steps and grid steps. The factor is {factor} and unstability will occur! Consider decrease the time step or increase the grid step.')\n",
    "\n",
    "        # Check dt size setting\n",
    "        if self.dt > self.total_time/2:\n",
    "            raise ValueError('The time step is too big.')\n",
    "\n",
    "        # Check dx size setting\n",
    "        if self.dt > self.total_time/3:\n",
    "            raise ValueError('The grid step is too big.')\n",
    "\n",
    "    def make_heat_source_func(self, Q):\n",
    "        if callable(Q):\n",
    "            return torch.compile(Q)\n",
    "        else:\n",
    "            def func(x, y, t):\n",
    "                return Q\n",
    "            return torch.compile(func)\n",
    "\n",
    "    def set_ic(self):\n",
    "        # print(self.grid[1:-1,1:-1].shape)\n",
    "        self.grid[1:-1,1:-1] = self.ic(self.x_coord_tensor, self.y_coord_tensor)\n",
    "\n",
    "    def set_bc(self):\n",
    "        self.bc.apply(self)\n",
    "\n",
    "    def make_grid(self):\n",
    "        # Get size of grid\n",
    "        self.x_grid = math.ceil(self.map_shape[1] / self.dx)\n",
    "        self.y_grid = math.ceil(self.map_shape[0] / self.dx)\n",
    "        self.grid = torch.zeros(self.y_grid+2, self.x_grid+2, dtype=self.dtype, device=self.device)\n",
    "\n",
    "        # For convenience, prevent overhead for unsqueeze\n",
    "        self.grid_ch = self.grid.unsqueeze(0).unsqueeze(0).expand(1,1,-1,-1)\n",
    "\n",
    "    def make_conv_core_continuous(self):\n",
    "        self.conv = nn.Conv2d(1, 4, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype)\n",
    "        dt_dx2 = self.dt / (self.dx**2)\n",
    "        kernel = torch.tensor([\n",
    "            [[ [0,0,0], [1,-1,0], [0,0,0] ]],\n",
    "            [[ [0,0,0], [0,-1,1], [0,0,0] ]],\n",
    "            [[ [0,1,0], [0,-1,0], [0,0,0] ]],\n",
    "            [[ [0,0,0], [0,-1,0], [0,1,0] ]]\n",
    "        ], device=self.device, dtype=self.dtype) * dt_dx2\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = kernel\n",
    "\n",
    "\n",
    "    def make_conv_core_const(self):\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=(3,3), bias=False, device=self.device, dtype=self.dtype)\n",
    "        dt_dx2 = self.dt / (self.dx**2)\n",
    "        kernel = torch.tensor([\n",
    "            [[ [0,1,0], [1,-4,1], [0,1,0] ]],\n",
    "        ], device=self.device, dtype=self.dtype) * dt_dx2 * self.c\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.conv.weight[:] = kernel\n",
    "\n",
    "    def decide_computation_mode(self):\n",
    "        if isinstance(self.c, ContConduct):\n",
    "            self.update = self.update_continuous\n",
    "            self.make_conv_core_continuous()\n",
    "        else:\n",
    "            self.update = self.update_const\n",
    "            self.make_conv_core_const()\n",
    "\n",
    "    @torch.compile\n",
    "    def update_continuous(self):\n",
    "        with torch.inference_mode():\n",
    "            diff_map = self.conv(self.grid_ch)\n",
    "            diff = torch.sum(diff_map * self.c.merge_map, dim=1, keepdim=True) + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff\n",
    "\n",
    "    # @torch.compile\n",
    "    # def update_continuous(self):\n",
    "    #     with torch.inference_mode():\n",
    "    #         diff0 = self.conv[0](self.grid_ch)\n",
    "    #         diff1 = self.conv[1](self.grid_ch)\n",
    "    #         diff2 = self.conv[2](self.grid_ch)\n",
    "    #         diff3 = self.conv[3](self.grid_ch)\n",
    "    #\n",
    "    #         self.grid_ch[:, :, 1:-1, 1:-1] += diff0 + diff1 + diff2 + diff3 + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "\n",
    "    @torch.compile\n",
    "    def update_const(self):\n",
    "        with torch.inference_mode():\n",
    "            diff = self.conv(self.grid_ch)\n",
    "            self.grid_ch[:, :, 1:-1, 1:-1] += diff + self.Q(self.x_coord_tensor, self.y_coord_tensor, self.cur_time) * self.dt\n",
    "            # self.add_const_diff(diff)\n",
    "\n",
    "    # @torch.compile\n",
    "    # def add_const_diff(self, diff):\n",
    "    #     with torch.inference_mode():\n",
    "    #         self.grid_ch[:, :, 1:-1, 1:-1] += diff + self.Q(self.x_coord_tensor, self.y_coord_tensor,\n",
    "    #                                                         self.cur_time) * self.dt\n",
    "\n",
    "    # @torch.compile\n",
    "    def start(self):\n",
    "        saved = []\n",
    "        append = saved.append\n",
    "        cur_max = -float('inf')\n",
    "        cur_min = float('inf')\n",
    "        with torch.inference_mode():\n",
    "            for step in tqdm(range( int(self.total_time/self.dt) ),disable=not self.do_progress_bar):\n",
    "                self.set_bc()\n",
    "                self.update()\n",
    "                self.cur_time += self.dt\n",
    "\n",
    "                if step % self.plot_step == 0:\n",
    "                    copied = self.grid[1:-1,1:-1].clone().to('cpu')\n",
    "                    if self.dtype == torch.bfloat16:\n",
    "                        copied = copied.to(dtype=torch.float32)\n",
    "                    append(copied)\n",
    "\n",
    "                    this_max = torch.max(self.grid[1:-1,1:-1])\n",
    "                    if cur_max < this_max:\n",
    "                        cur_max = this_max\n",
    "\n",
    "                    this_min = torch.min(self.grid[1:-1,1:-1])\n",
    "                    if cur_min > this_min:\n",
    "                        cur_min = this_min\n",
    "\n",
    "        # Append the very final result\n",
    "\n",
    "        copied = self.grid[1:-1,1:-1].clone().to('cpu')\n",
    "\n",
    "        if self.dtype == torch.bfloat16:\n",
    "            copied = copied.to(dtype=torch.float32)\n",
    "        append(copied)\n",
    "        # copied#.to('cpu')\n",
    "        if self.if_plot:\n",
    "            fig, axis = plt.subplots()\n",
    "\n",
    "\n",
    "            pcm = axis.pcolormesh(self.grid.to(dtype=torch.float32).cpu().numpy()[1:-1,1:-1], cmap=plt.cm.jet,\n",
    "                                  vmin=float(cur_min), vmax=float(cur_max))\n",
    "            plt.colorbar(pcm, ax=axis)\n",
    "            axis.set_xlabel('x grids')\n",
    "            axis.set_ylabel('y grids')\n",
    "\n",
    "\n",
    "\n",
    "            for i, data in enumerate(saved):\n",
    "                pcm.set_array(data.numpy())\n",
    "                axis.set_title(f'Distribution at t={i * self.plot_step * self.dt:.4f}')\n",
    "                plt.pause(0.01)\n",
    "\n",
    "            plt.show()"
   ],
   "id": "8dedae324778bc3b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:28:44.839550Z",
     "start_time": "2025-05-07T01:28:44.833547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "map_shape=(torch.pi, torch.pi)\n",
    "dx = 0.05\n",
    "total_time=1\n",
    "dt=0.00005\n",
    "# dt = 0.05\n",
    "\n",
    "\n",
    "def ic(x,y):\n",
    "    return torch.sin(x) * torch.sin(y)\n",
    "    # return torch.sin(x)\n",
    "    # return 0\n",
    "c=0.5\n",
    "plot_step=100\n",
    "\n",
    "def Q(x,y,t):\n",
    "    # res = -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5\n",
    "    # if t < 0.5:\n",
    "    #     return res\n",
    "    # return -res\n",
    "    return -torch.sin(5*x) * torch.sin(5*y) * torch.cos( torch.sqrt( (x-torch.pi/2)**2 + (y-torch.pi/2)**2) *4) * 5 * math.sin(t*torch.pi*8)\n",
    "\n",
    "factor = dt*c*2/dx**2\n",
    "print(factor)\n",
    "\n",
    "\n",
    "def func(x,y):\n",
    "    return 0.5\n",
    "con = ContConduct(func)\n",
    "\n",
    "\n",
    "def func2(x,y,t):\n",
    "    # return (torch.where(y < torch.pi/5, -1, 1) + torch.where(y > 2*torch.pi/5, -1, 1) - 1\n",
    "    #         + torch.where(y < 3*torch.pi/5, -1, 1) + torch.where(y > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(y < torch.pi/4, 0, 1) + torch.where(y > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "\n",
    "def func3(x,y,t):\n",
    "    # return (torch.where(x < torch.pi/5, -1, 1) + torch.where(x > 2*torch.pi/5, -1, 1) - 1 +\n",
    "    #         torch.where(x < 3*torch.pi/5, -1, 1) + torch.where(x > 4*torch.pi/5, -1, 1) - 1)\n",
    "    return (torch.where(x < torch.pi/4, 0, 1) + torch.where(x > 3*torch.pi/4, 0, 1) - 1)# * math.sin(4*torch.pi*t)\n",
    "    # return 0\n",
    "\n",
    "bc= BC_2D((1,0,func2),(1,0,func2),(1,0,func3),(1,0,func3))\n"
   ],
   "id": "5c7536d3907a3921",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019999999999999997\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:02:07.161717Z",
     "start_time": "2025-05-06T16:01:51.501839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_plot=False)\n",
    "test.start()"
   ],
   "id": "94fd66fde62a9986",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Your simulation will be performed based on CUDA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 12:01:56.180000 27108 .conda\\Lib\\site-packages\\torch\\_inductor\\utils.py:1250] [5/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-07T01:30:11.546122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====================================================================================')\n",
    "print('Simulation session benchmark on constant conductivity with optimization with float64')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float64, if_plot=False)\n",
    "%timeit test.start()\n",
    "print('====================================================================================')"
   ],
   "id": "84ecc741ce8047d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Simulation session benchmark on constant conductivity with optimization with float64\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T16:44:25.249983Z",
     "start_time": "2025-05-06T16:42:43.264094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('====================================================================================')\n",
    "print('Simulation session benchmark on constant conductivity with optimization')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, c, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_plot=False)\n",
    "%timeit test.start()\n",
    "print('====================================================================================')\n",
    "print('Simulation session benchmark on constant conductivity with optimization')\n",
    "test = Heat2dSimu(map_shape, dx, total_time, dt, bc, ic, con, plot_step, Q, device='cuda', do_progress_bar=False, dtype=torch.float32, if_plot=False)\n",
    "%timeit test.start()\n",
    "print('====================================================================================')"
   ],
   "id": "c0514861578fe1af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Simulation session benchmark on constant conductivity with optimization\n",
      "6.07 s ± 75.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "====================================================================================\n",
      "Simulation session benchmark on constant conductivity with optimization\n",
      "6.59 s ± 56 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:06:58.386301Z",
     "start_time": "2025-05-07T01:06:58.383034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ratio_std(m_old, s_old, m_new, s_new):\n",
    "    ratio = 1 - m_new/m_old\n",
    "    n1 = (s_old**2 + s_new**2) / m_old**2\n",
    "    n2 = (m_old - m_new) * s_old / m_old**2\n",
    "    n2 = n2**2\n",
    "    sigma = math.sqrt(n1 + n2)\n",
    "    print(ratio*100, sigma*100)"
   ],
   "id": "620227ec202efc70",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:08:36.938785Z",
     "start_time": "2025-05-07T01:08:36.934786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m_old, s_old, m_new, s_new = 16.6, 0.38, 6.07, 0.0759\n",
    "ratio_std(m_old, s_old, m_new, s_new)\n",
    "\n",
    "m_old, s_old, m_new, s_new = 18.1, 0.297, 6.59, 0.056\n",
    "ratio_std(m_old, s_old, m_new, s_new)"
   ],
   "id": "d33777937f9e6462",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.433734939759034 2.7491605314090015\n",
      "63.59116022099448 1.969016669876732\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
